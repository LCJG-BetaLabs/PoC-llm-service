version: '3'

services:
  llm-service:
    image: ghcr.io/open-webui/open-webui:ollama
    restart: always
    ports:
      - "3000:8080"
    volumes:
      - ./ollama:/root/.ollama
      - ./open-webui:/app/backend/data